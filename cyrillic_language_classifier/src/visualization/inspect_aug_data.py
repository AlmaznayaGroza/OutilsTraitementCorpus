"""Script d'inspection et d'analyse qualitative des donnÃ©es augmentÃ©es

Ce script fournit des outils pour Ã©valuer la qualitÃ© et la cohÃ©rence
des donnÃ©es gÃ©nÃ©rÃ©es par le processus d'augmentation de corpus multilingue.
Il implÃ©mente une sÃ©rie d'analyses comparatives entre les donnÃ©es originales
et augmentÃ©es pour valider l'efficacitÃ© des stratÃ©gies d'augmentation.

Analyses principales implÃ©mentÃ©es:
    * comparaison des distributions de longueur entre corpus original et augmentÃ©
    * Ã©valuation de l'Ã©quilibrage linguistique aprÃ¨s augmentation
    * analyse de l'entropie pour mesurer la diversitÃ© des distributions
    * inspection des caractÃ©ristiques textuelles par mÃ©thode d'augmentation
    * validation de la cohÃ©rence des mÃ©tadonnÃ©es entre les ensembles

MÃ©thodologie d'Ã©valuation:
    Le script suit une approche quantitative rigoureuse qui compare les
    propriÃ©tÃ©s statistiques des donnÃ©es avant et aprÃ¨s augmentation.
    Cette validation est cruciale pour s'assurer que l'augmentation
    amÃ©liore effectivement l'Ã©quilibrage du corpus sans introduire de biais
    ou de distorsions significatives dans les distributions linguistiques.

Architecture d'analyse :
    Les analyses sont organisÃ©es selon une hiÃ©rarchie logique qui progresse
    des statistiques descriptives gÃ©nÃ©rales vers des analyses spÃ©cialisÃ©es
    par mÃ©thode d'augmentation. Cette approche systÃ©matique facilite
    l'identification rapide des succÃ¨s et des limitations du processus
    d'augmentation.

Applications de validation:
    AdaptÃ© pour valider la qualitÃ© des corpus augmentÃ©s destinÃ©s
    Ã  l'entraÃ®nement de modÃ¨les de traitement automatique des langues,
    oÃ¹ l'Ã©quilibrage et la representativitÃ© des donnÃ©es sont cruciaux pour
    la performance et l'Ã©quitÃ© des systÃ¨mes dÃ©veloppÃ©s.
"""


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import glob
from typing import Dict


# =============================================================================
# CONSTANTES DE CONFIGURATION POUR L'ANALYSE DES DONNÃ‰ES AUGMENTÃ‰ES
# =============================================================================

# Configuration des rÃ©pertoires de donnÃ©es
DATA_PATHS = {
    'original_pattern': 'data/processed/merged/*_articles.csv',
    'augmented_file': 'data/processed/augmented/all_augmented_articles.csv',
    'output_base': 'results/figures/augmentation',
    'metrics_base': 'results/metrics/augmentation'
}

# ParamÃ¨tres de visualisation
VISUALIZATION_CONFIG = {
    'figure_size': (12, 8),
    'priority_figure_size': (14, 8),
    'heatmap_figure_size': (12, 10),
    'dpi': 300,
    'style': 'seaborn-v0_8-whitegrid'
}

# Configuration des couleurs pour les comparaisons
COLOR_SCHEMES = {
    'comparison_palette': ['#1f77b4', '#ff7f0e'], # bleu/orange pour original/augmentÃ©
    'methods_palette': 'Set2',                        # palette pour les mÃ©thodes d'augmentation
    'heatmap_colormap': 'YlGnBu'                      # pour les heatmaps
}

# Langues prioritaires pour l'analyse approfondie
PRIORITY_LANGUAGES = ['ab', 'kbd', 'koi', 'kv', 'mhr']

# MÃ©thodes d'augmentation attendues
AUGMENTATION_METHODS = [
    'data_augmentation',
    'cross_language_augmentation', 
    'data_perturbation'
]

# ParamÃ¨tres statistiques
STATISTICAL_CONFIG = {
    'histogram_bins': 30,
    'entropy_precision': 4,
    'percentage_precision': 1,
    'sample_size_examples': 3
}


# =================================================
# FONCTIONS UTILITAIRES POUR L'ANALYSE COMPARATIVE
# =================================================


def setup_analysis_environment() -> None:
    """Configure l'environnement d'analyse et les paramÃ¨tres
    
    Cette fonction initialise Matplotlib et Weaborn avec des paramÃ¨tres
    adaptÃ©s Ã  l'analyse comparative de donnÃ©es, afin de garantir
    une cohÃ©rence visuelle dans toutes les visualisations gÃ©nÃ©rÃ©es.
    
    La configuration privilÃ©gie la lisibilitÃ©.
    """
    plt.style.use(VISUALIZATION_CONFIG['style'])
    plt.rcParams['figure.figsize'] = VISUALIZATION_CONFIG['figure_size']
    plt.rcParams['savefig.dpi'] = VISUALIZATION_CONFIG['dpi']
    plt.rcParams['font.size'] = 11
    
    # CrÃ©er les dossiers de sortie si nÃ©cessaire
    os.makedirs(DATA_PATHS['output_base'], exist_ok=True)
    os.makedirs(DATA_PATHS['metrics_base'], exist_ok=True)


def load_original_corpus() -> pd.DataFrame:
    """Charge et unifie tous les fichiers du corpus original
    
    Cette fonction rassemble tous les fichiers de donnÃ©es originales
    en un DataFrame unifiÃ©, permettant une comparaison cohÃ©rente avec
    les donnÃ©es augmentÃ©es. Elle applique une validation de base pour
    s'assurer de la cohÃ©rence des donnÃ©es chargÃ©es.
    
    Returns:
        pd.DataFrame: corpus original unifiÃ© avec marquage de source
        
    Raises:
        FileNotFoundError: si aucun fichier original n'est trouvÃ©
        ValueError: si les donnÃ©es chargÃ©es sont incohÃ©rentes
        
    Note:
        La fonction ajoute automatiquement une colonne 'source_corpus'
        marquÃ©e comme 'original' pour faciliter les comparaisons ultÃ©rieures.
    """
    original_files = glob.glob(DATA_PATHS['original_pattern'])
    
    if not original_files:
        raise FileNotFoundError(
            f"Aucun fichier original trouvÃ©: "
            f"{DATA_PATHS['original_pattern']}"
        )
    
    original_dfs = []
    for file in original_files:
        try:
            df = pd.read_csv(file)
            df['source_corpus'] = 'original'
            original_dfs.append(df)
        except Exception as e:
            print(f"Erreur lors du chargement de {file}: {e}")
            continue
    
    if not original_dfs:
        raise ValueError("Aucun fichier original valide n'a pu Ãªtre chargÃ©")
    
    combined_original = pd.concat(original_dfs, ignore_index=True)
    print(f"Corpus original chargÃ© : {len(combined_original):,} articles")
    
    return combined_original


def load_augmented_corpus() -> pd.DataFrame:
    """Charge le corpus augmentÃ© avec validation de cohÃ©rence
    
    Cette fonction charge le fichier de donnÃ©es augmentÃ©es et applique
    une validation pour s'assurer que les colonnes nÃ©cessaires sont
    prÃ©sentes et que les donnÃ©es sont cohÃ©rentes pour l'analyse comparative.
    
    Returns:
        pd.DataFrame: corpus augmentÃ© avec marquage de source
        
    Raises:
        FileNotFoundError: si le fichier augmentÃ© n'existe pas
        ValueError: si le fichier augmentÃ© est vide ou invalide
        
    Note:
        La fonction ajoute une colonne 'source_corpus' marquÃ©e comme 'augmented'
        et valide la prÃ©sence des colonnes essentielles pour l'analyse.
    """
    augmented_path = DATA_PATHS['augmented_file']
    
    if not os.path.exists(augmented_path):
        raise FileNotFoundError(f"Fichier augmentÃ© non trouvÃ©: {augmented_path}")
    
    try:
        augmented_df = pd.read_csv(augmented_path)
        
        if augmented_df.empty:
            raise ValueError("Le fichier de donnÃ©es augmentÃ©es est vide")
        
        # Validation des colonnes essentielles
        required_columns = ['language', 'text', 'token_count', 'source']
        missing_columns = [
            col for col in required_columns
            if col not in augmented_df.columns
        ]
        
        if missing_columns:
            print(f"Colonnes manquantes dans les donnÃ©es augmentÃ©es: {missing_columns}")
        
        augmented_df['source_corpus'] = 'augmented'
        print(f"Corpus augmentÃ© chargÃ© : {len(augmented_df):,} articles")
        
        return augmented_df
        
    except Exception as e:
        raise ValueError(f"Erreur lors du chargement des donnÃ©es augmentÃ©es: {e}")


def calculate_distribution_entropy(
        df: pd.DataFrame,
        column: str = 'language'
) -> float:
    """Calcule l'entropie de Shannon pour une distribution de donnÃ©es

    Cette fonction mesure la diversitÃ© d'une distribution en calculant
    son entropie de Shannon. Une entropie plus Ã©levÃ©e indique une
    distribution plus Ã©quilibrÃ©e, ce qui est gÃ©nÃ©ralement souhaitable
    pour les corpus d'entraÃ®nement de modÃ¨les de machine learning.
    Cette mÃ©trique est particuliÃ¨rement utile pour Ã©valuer
    l'efficacitÃ© des stratÃ©gies d'augmentation de donnÃ©es.
    
    Args:
        df (pd.DataFrame): DataFrame contenant les donnÃ©es Ã  analyser
        column (str): nom de la colonne pour calculer l'entropie
        
    Returns:
        float: entropie de Shannon en bits (0.0 si DataFrame vide)
    """
    if len(df) == 0:
        return 0.0
    
    # Calculer la distribution des valeurs
    value_counts = df[column].value_counts()
    probabilities = value_counts / value_counts.sum()
    
    # Calculer l'entropie de Shannon
    entropy = -np.sum(probabilities * np.log2(probabilities))
    
    return entropy


def generate_comparison_statistics(
        original_df: pd.DataFrame, 
        augmented_df: pd.DataFrame
) -> Dict:
    """GÃ©nÃ¨re des statistiques comparatives complÃ¨tes entre les corpus
    
    Cette fonction calcule un ensemble complet de mÃ©triques comparatives
    qui permettent d'Ã©valuer quantitativement l'impact du processus
    d'augmentation sur les caractÃ©ristiques du corpus.
    
    Args:
        original_df (pd.DataFrame): corpus original
        augmented_df (pd.DataFrame): corpus augmentÃ©
        
    Returns:
        Dict: dictionnaire contenant toutes les statistiques comparatives
        
    MÃ©triques calculÃ©es:
        - tailles des corpus et gains relatifs
        - entropies des distributions linguistiques
        - statistiques de longueur (moyenne, mÃ©diane, Ã©cart-type)
        - nombres de langues uniques et distributions
        - mÃ©triques de diversitÃ© et d'Ã©quilibrage
    """
    stats = {
        # Stats de base
        'original_size': len(original_df),
        'augmented_size': len(augmented_df),
        'total_size': len(original_df) + len(augmented_df),
        
        # Calcul des gains
        'augmentation_ratio': (
            len(augmented_df) / len(original_df)
            if len(original_df) > 0 else 0
        ),
        'augmentation_percentage': (
            (len(augmented_df) / len(original_df)) * 100
            if len(original_df) > 0 else 0
        ),
        
        # Entropies des distributions linguistiques
        'original_entropy': calculate_distribution_entropy(original_df),
        'augmented_entropy': calculate_distribution_entropy(augmented_df),
        
        # Stats de longueur
        'original_avg_length': (
            original_df['token_count'].mean()
            if 'token_count' in original_df.columns else 0
        ),
        'augmented_avg_length': (
            augmented_df['token_count'].mean()
            if 'token_count' in augmented_df.columns else 0
        ),
        
        # DiversitÃ© linguistique
        'original_languages': (
            original_df['language'].nunique()
            if 'language' in original_df.columns else 0
        ),
        'augmented_languages': (
            augmented_df['language'].nunique()
            if 'language' in augmented_df.columns else 0
        ),
    }
    
    # Calcul de l'entropie combinÃ©e pour mesurer l'effet global
    if not original_df.empty and not augmented_df.empty:
        combined_df = pd.concat([original_df, augmented_df], ignore_index=True)
        stats['combined_entropy'] = calculate_distribution_entropy(combined_df)
    else:
        stats['combined_entropy'] = 0.0
    
    return stats


# ====================================================
# FONCTIONS D'ANALYSE ET DE VISUALISATION PRINCIPALES
# ====================================================

def analyze_length_distributions(combined_df: pd.DataFrame) -> None:
    """Analyse comparative des distributions de longueur entre corpus
    
    Cette fonction gÃ©nÃ¨re des visualisations comparatives qui permettent
    d'Ã©valuer si l'augmentation a prÃ©servÃ© les caractÃ©ristiques de longueur
    du corpus original ou si elle a introduit des biais de longueur.
    
    Args:
        combined_df (pd.DataFrame): corpus combinÃ© (original + augmentÃ©)
        
    L'analyse produit des histogrammes comparatifs et des statistiques
    descriptives qui rÃ©vÃ¨lent l'impact de l'augmentation sur la distribution
    des longueurs de texte, un facteur crucial pour la qualitÃ© du corpus.
    """
    plt.figure(figsize=VISUALIZATION_CONFIG['figure_size'])
    
    # Histogrammes comparatifs des longueurs
    sns.histplot(
        data=combined_df, 
        x='token_count', 
        hue='source_corpus',
        bins=STATISTICAL_CONFIG['histogram_bins'], 
        kde=True, 
        element='step',
        palette=COLOR_SCHEMES['comparison_palette']
    )
    
    plt.title('Comparaison des distributions de longueur d\'articles')
    plt.xlabel('Nombre de tokens')
    plt.ylabel('Nombre d\'articles')
    plt.legend(title='Source du corpus', labels=['Original', 'AugmentÃ©'])
    plt.grid(True, alpha=0.3)
    
    # Sauvegarder la visualisation
    output_path = os.path.join(
        DATA_PATHS['output_base'],
        'length_distribution_comparison.png'
    )
    plt.savefig(
        output_path,
        dpi=VISUALIZATION_CONFIG['dpi'],
        bbox_inches='tight'
    )
    plt.close()
    
    print(f"âœ… Analyse des distributions de longueur sauvegardÃ©e: {output_path}")


def analyze_language_balance(combined_df: pd.DataFrame) -> None:
    """Analyse de l'Ã©quilibrage linguistique aprÃ¨s augmentation
    
    Cette fonction Ã©value l'efficacitÃ© de l'augmentation pour amÃ©liorer
    l'Ã©quilibrage entre les langues, particuliÃ¨rement importante pour
    les langues sous-reprÃ©sentÃ©es dans le corpus original.
    
    Args:
        combined_df (pd.DataFrame): corpus combinÃ© avec marquage de source
        
    L'analyse gÃ©nÃ¨re des visualisations qui montrent la rÃ©partition
    linguistique avant et aprÃ¨s augmentation, permettant d'identifier
    les langues qui ont le plus bÃ©nÃ©ficiÃ© du processus d'augmentation.
    """
    # Statistiques par langue et par source
    lang_stats = combined_df.groupby(['language', 'source_corpus']).agg(
        article_count=('title', 'count'),
        avg_tokens=('token_count', 'mean')
    ).reset_index()
    
    # Tableau pivot pour la visualisation
    lang_pivot = lang_stats.pivot(
        index='language',
        columns='source_corpus',
        values='article_count'
    ).fillna(0)
    
    # Calculer les pourcentages d'augmentation par langue
    if 'original' in lang_pivot.columns and 'augmented' in lang_pivot.columns:
        lang_pivot['augmentation_ratio'] = (
            lang_pivot['augmented'] / lang_pivot['original'].replace(0, 1)
        )
   
    # Visualisation comparative pour les langues prioritaires
    priority_df = combined_df[combined_df['language'].isin(PRIORITY_LANGUAGES)]
    
    if not priority_df.empty:
        plt.figure(figsize=VISUALIZATION_CONFIG['priority_figure_size'])
        sns.boxplot(
            data=priority_df, 
            x='language', 
            y='token_count', 
            hue='source_corpus',
            palette=COLOR_SCHEMES['comparison_palette']
        )
        plt.title('Comparaison des longueurs pour les langues prioritaires')
        plt.xlabel('Langue')
        plt.ylabel('Nombre de tokens')
        plt.legend(title='Source', labels=['Original', 'AugmentÃ©'])
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        plt.tight_layout()
        
        output_path = os.path.join(
            DATA_PATHS['output_base'],
            'priority_langs_comparison.png'
        )
        plt.savefig(
            output_path,
            dpi=VISUALIZATION_CONFIG['dpi'],
            bbox_inches='tight'
        )
        plt.close()
        
        print(f"âœ… Analyse des langues prioritaires sauvegardÃ©e: {output_path}")


def analyze_augmentation_methods(augmented_df: pd.DataFrame) -> None:
    """Analyse dÃ©taillÃ©e des mÃ©thodes d'augmentation utilisÃ©es
    
    Cette fonction examine les caractÃ©ristiques spÃ©cifiques de chaque
    mÃ©thode d'augmentation pour Ã©valuer leur contribution respective
    Ã  la diversitÃ© et Ã  la qualitÃ© du corpus final.
    
    Args:
        augmented_df (pd.DataFrame): corpus augmentÃ© avec mÃ©tadonnÃ©es de mÃ©thodes
        
    L'analyse produit des visualisations qui permettent de comparer
    l'efficacitÃ© des diffÃ©rentes stratÃ©gies d'augmentation et d'identifier
    les mÃ©thodes les plus performantes pour chaque type de langue.
    """
    if 'source' not in augmented_df.columns:
        print("âš ï¸ Colonne 'source' manquante, analyse des mÃ©thodes ignorÃ©e")
        return
    
    # Distribution des longueurs par mÃ©thode d'augmentation
    plt.figure(figsize=VISUALIZATION_CONFIG['figure_size'])
    sns.boxplot(
        data=augmented_df,
        x='source',
        y='token_count',
        palette=COLOR_SCHEMES['methods_palette']
    )
    plt.title('Distribution des longueurs par mÃ©thode d\'augmentation')
    plt.xlabel('MÃ©thode d\'augmentation')
    plt.ylabel('Nombre de tokens')
    plt.xticks(rotation=45, ha='right')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    output_path = os.path.join(
        DATA_PATHS['output_base'],
        'length_by_method.png'
    )
    plt.savefig(
        output_path,
        dpi=VISUALIZATION_CONFIG['dpi'],
        bbox_inches='tight'
    )
    plt.close()
    
    # Heatmap des mÃ©thodes par langue
    method_lang_crosstab = pd.crosstab(
        index=augmented_df['language'],
        columns=augmented_df['source'],
        margins=False
    )
    
    plt.figure(figsize=VISUALIZATION_CONFIG['heatmap_figure_size'])
    sns.heatmap(
        method_lang_crosstab,
        annot=True,
        cmap=COLOR_SCHEMES['heatmap_colormap'],
        fmt='g',
        cbar_kws={'label': 'Nombre d\'articles'}
    )
    plt.title('RÃ©partition des articles par langue et mÃ©thode d\'augmentation')
    plt.xlabel('MÃ©thode d\'augmentation')
    plt.ylabel('Langue')
    plt.tight_layout()
    
    output_path = os.path.join(
        DATA_PATHS['output_base'],
        'language_method_heatmap.png'
    )
    plt.savefig(
        output_path,
        dpi=VISUALIZATION_CONFIG['dpi'],
        bbox_inches='tight'
    )
    plt.close()
    
    print(f"âœ… Analyse des mÃ©thodes d'augmentation sauvegardÃ©e: {output_path}")


def generate_entropy_analysis(
        original_df: pd.DataFrame, 
        augmented_df: pd.DataFrame, 
        combined_df: pd.DataFrame
) -> None:
    """Analyse de l'entropie pour mesurer l'amÃ©lioration de la diversitÃ©
    
    Cette fonction calcule et visualise les mÃ©triques d'entropie qui
    quantifient objectivement l'amÃ©lioration de l'Ã©quilibrage linguistique
    apportÃ©e par le processus d'augmentation.
    
    Args:
        original_df (pd.DataFrame): corpus original
        augmented_df (pd.DataFrame): corpus augmentÃ©
        combined_df (pd.DataFrame): corpus combinÃ©
        
    L'analyse d'entropie fournit une mesure quantitative de la diversitÃ©
    qui permet d'Ã©valuer objectivement l'efficacitÃ© des stratÃ©gies
    d'augmentation pour crÃ©er des corpus plus Ã©quilibrÃ©s.
    """
    # Calculer les entropies
    original_entropy = calculate_distribution_entropy(original_df)
    augmented_entropy = calculate_distribution_entropy(augmented_df)
    combined_entropy = calculate_distribution_entropy(combined_df)
    
    # Visualisation comparative des entropies
    entropies = [original_entropy, augmented_entropy, combined_entropy]
    corpus_types = ['Original', 'AugmentÃ©', 'CombinÃ©']
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']
    
    plt.figure(figsize=VISUALIZATION_CONFIG['figure_size'])
    bars = plt.bar(corpus_types, entropies, color=colors, alpha=0.7)
    plt.title('Entropie de la distribution des langues par corpus')
    plt.ylabel('Entropie (bits)')
    plt.grid(axis='y', alpha=0.3)
    
    # Ajouter les valeurs sur les barres
    for bar, entropy in zip(bars, entropies):
        height = bar.get_height()
        plt.text(
            bar.get_x() + bar.get_width()/2., height + 0.01,
            f'{entropy:.{STATISTICAL_CONFIG["entropy_precision"]}f}',
            ha='center', va='bottom', fontweight='bold'
        )
    
    plt.tight_layout()
    
    output_path = os.path.join(
        DATA_PATHS['output_base'],
        'language_entropy.png'
    )
    plt.savefig(
        output_path,
        dpi=VISUALIZATION_CONFIG['dpi'],
        bbox_inches='tight'
    )
    plt.close()
    
    print(f"âœ… Analyse d'entropie sauvegardÃ©e: {output_path}")
    
    # Afficher les rÃ©sultats numÃ©riques
    print(f"\nğŸ“Š RÃ©sultats de l'analyse d'entropie:")
    print(
        f"   â€¢ Corpus original     : {
        original_entropy:.{STATISTICAL_CONFIG['entropy_precision']}f
        } bits"
    )
    print(
        f"   â€¢ Corpus augmentÃ©     : {
        augmented_entropy:.{STATISTICAL_CONFIG['entropy_precision']}f
        } bits"
    )
    print(
        f"   â€¢ Corpus combinÃ©      : {
        combined_entropy:.{STATISTICAL_CONFIG['entropy_precision']}f
        } bits"
    )


# ==================================
# FONCTION PRINCIPALE D'INSPECTION
# ==================================

def inspect_augmentation_quality() -> Dict:
    """
    ExÃ©cute l'inspection complÃ¨te de la qualitÃ© des donnÃ©es augmentÃ©es
    
    Cette fonction orchestre l'ensemble du processus d'analyse comparative
    entre les donnÃ©es originales et augmentÃ©es, et produit un rapport
    complet sur l'efficacitÃ© et la qualitÃ© du processus d'augmentation.
    
    Returns:
        Dict: dictionnaire contenant toutes les statistiques d'analyse
        
    Raises:
        FileNotFoundError: si les fichiers de donnÃ©es requis sont manquants
        ValueError: si les donnÃ©es chargÃ©es sont incohÃ©rentes ou invalides
        
    Le processus d'inspection comprend:
        1. configuration de l'environnement d'analyse
        2. chargement et validation des corpus original et augmentÃ©
        3. gÃ©nÃ©ration des statistiques comparatives
        4. analyses visuelles des distributions et caractÃ©ristiques
        5. Ã©valuation quantitative de l'amÃ©lioration de l'Ã©quilibrage
        6. gÃ©nÃ©ration d'un rapport de synthÃ¨se complet
        
    Cette fonction constitue le point d'entrÃ©e principal pour l'Ã©valuation
    de la qualitÃ© des donnÃ©es augmentÃ©es et peut Ãªtre utilisÃ©e comme
    validation automatisÃ©e dans un pipeline de traitement de donnÃ©es.
    """
    
    print("ğŸ” DÃ©marrage de l'inspection de la qualitÃ© des donnÃ©es augmentÃ©es")
    
    try:
        # 1. Configuration de l'environnement
        setup_analysis_environment()
        
        # 2. Chargement des donnÃ©es
        print("\nğŸ“‚ Chargement des corpus...")
        original_df = load_original_corpus()
        augmented_df = load_augmented_corpus()
        
        # 3. Combinaison des corpus pour l'analyse comparative
        combined_df = pd.concat([original_df, augmented_df], ignore_index=True)
        
        # 4. GÃ©nÃ©ration des statistiques comparatives
        print("\nğŸ“Š Calcul des statistiques comparatives...")
        stats = generate_comparison_statistics(original_df, augmented_df)
        
        # 5. Analyses visuelles et rapports
        print("\nğŸ“ˆ GÃ©nÃ©ration des analyses visuelles...")
        analyze_length_distributions(combined_df)
        analyze_language_balance(combined_df)
        analyze_augmentation_methods(augmented_df)
        generate_entropy_analysis(original_df, augmented_df, combined_df)
        
        # 6. Affichage du rÃ©sumÃ© des rÃ©sultats
        print("\n" + "="*60)
        print("RÃ‰SUMÃ‰ DE L'INSPECTION DES DONNÃ‰ES AUGMENTÃ‰ES")
        print("="*60)
        
        print(f"ğŸ“Š Tailles des corpus:")
        print(f"   â€¢ Articles originaux      : {stats['original_size']:,}")
        print(f"   â€¢ Articles augmentÃ©s      : {stats['augmented_size']:,}")
        print(f"   â€¢ Total combinÃ©           : {stats['total_size']:,}")
        print(f"   â€¢ Ratio d'augmentation    : {stats['augmentation_ratio']:.2f}x")
        print(
            f"   â€¢ Pourcentage d'augmentation : +{
            stats['augmentation_percentage']:.{STATISTICAL_CONFIG['percentage_precision']}f
            }%"
        )
        
        print(f"\nğŸŒ DiversitÃ© linguistique:")
        print(f"   â€¢ Langues originales      : {stats['original_languages']}")
        print(f"   â€¢ Langues augmentÃ©es      : {stats['augmented_languages']}")
        
        print(f"\nğŸ“ Longueurs moyennes:")
        print(f"   â€¢ Corpus original         : {stats['original_avg_length']:.1f} tokens")
        print(f"   â€¢ Corpus augmentÃ©         : {stats['augmented_avg_length']:.1f} tokens")
        
        print(f"\nğŸ² Entropie des distributions:")
        print(
            f"   â€¢ Corpus original         : {
            stats['original_entropy']:.{STATISTICAL_CONFIG['entropy_precision']}f
            } bits"
        )
        print(
            f"   â€¢ Corpus augmentÃ©         : {
            stats['augmented_entropy']:.{STATISTICAL_CONFIG['entropy_precision']}f
            } bits"
        )
        print(
            f"   â€¢ Corpus combinÃ©          : {
            stats['combined_entropy']:.{STATISTICAL_CONFIG['entropy_precision']}f
            } bits"
        )
        
        # 7. Exemples d'articles augmentÃ©s par mÃ©thode
        print(f"\nğŸ“ Exemples d'articles augmentÃ©s:")
        if 'source' in augmented_df.columns:
            for method in AUGMENTATION_METHODS:
                method_articles = augmented_df[augmented_df['source'] == method]
                if not method_articles.empty:
                    sample_size = min(
                        STATISTICAL_CONFIG['sample_size_examples'],
                        len(method_articles)
                    )
                    samples = method_articles.sample(sample_size)
                    
                    print(f"\n   {method.replace('_', ' ').title()} :")
                    for i, (_, article) in enumerate(samples.iterrows(), 1):
                        title = article['title'] if 'title' in article else f"Article_{i}"
                        language = article['language'] if 'language' in article else 'Unknown'
                        token_count = article['token_count'] if 'token_count' in article else 0
                        text_preview = (
                            str(article['text'])[:100] + "..."
                            if 'text' in article else "Pas de texte"
                        )
                        
                        print(f"     â€¢ {title} ({language}, {token_count} tokens)")
                        print(f"       {text_preview}")
        
        print(f"\nğŸ“ Visualisations sauvegardÃ©es dans: {DATA_PATHS['output_base']}")
        print("="*60)
        
        # 8. Sauvegarde des statistiques
        stats_output = os.path.join(DATA_PATHS['metrics_base'], 'augmentation_stats.txt')
        with open(stats_output, 'w', encoding='utf-8') as f:
            f.write("=== RAPPORT D'INSPECTION DES DONNÃ‰ES AUGMENTÃ‰ES ===\n\n")
            f.write(f"Corpus original : {stats['original_size']:,} articles\n")
            f.write(f"Corpus augmentÃ© : {stats['augmented_size']:,} articles\n")
            f.write(f"Ratio d'augmentation : {stats['augmentation_ratio']:.2f}x\n")
            f.write(f"Entropie originale : {stats['original_entropy']:.4f} bits\n")
            f.write(f"Entropie augmentÃ©e : {stats['augmented_entropy']:.4f} bits\n")
            f.write(f"Entropie combinÃ©e : {stats['combined_entropy']:.4f} bits\n")
        
        print(f"ğŸ“„ Rapport statistique sauvegardÃ©: {stats_output}")
        
        return stats
        
    except Exception as e:
        print(f"\nâŒ Erreur lors de l'inspection des donnÃ©es augmentÃ©es: {e}")
        raise


# =========================
# POINT D'ENTRÃ‰E PRINCIPAL
# =========================

if __name__ == "__main__":
    """Point d'entrÃ©e principal avec gestion d'erreurs complÃ¨te
    
    ExÃ©cute l'inspection complÃ¨te de la qualitÃ© des donnÃ©es augmentÃ©es
    avec gestion robuste des erreurs et affichage des rÃ©sultats.
    
    Usage:
        python inspect_aug_data.py
    """
    try:
        print("ğŸš€ Lancement de l'inspection des donnÃ©es augmentÃ©es...")
        
        # ExÃ©cution de l'inspection complÃ¨te
        inspection_results = inspect_augmentation_quality()
        
        print(f"\nâœ… Inspection terminÃ©e avec succÃ¨s !")
        print(
            f"ğŸ“Š {inspection_results['augmented_size']:,} "
            f"articles augmentÃ©s analysÃ©s"
        )
        print(
            f"ğŸ¯ AmÃ©lioration de l'Ã©quilibrage: "
            f"{inspection_results['augmentation_ratio']:.1f}x plus de donnÃ©es"
        )
        
        # Ã‰valuation qualitative basÃ©e sur les mÃ©triques
        if (
            inspection_results['combined_entropy'] > inspection_results['original_entropy']
        ):
            print("âœ¨ L'augmentation a amÃ©liorÃ© la diversitÃ© du corpus")
        else:
            print("âš ï¸ L'augmentation n'a pas significativement amÃ©liorÃ© la diversitÃ©")
        
    except KeyboardInterrupt:
        print("\nâŒ Processus interrompu par l'utilisateur")
        exit(1)
    except (FileNotFoundError, ValueError) as e:
        print(f"\nâŒ Erreur de donnÃ©es: {e}")
        print("ğŸ’¡ VÃ©rifiez la prÃ©sence et le format des fichiers de corpus")
        exit(1)
    except Exception as e:
        print(f"\nâŒ Erreur inattendue: {e}")
        print("ğŸ’¡ Consultez les logs pour plus de dÃ©tails")
        exit(1)
